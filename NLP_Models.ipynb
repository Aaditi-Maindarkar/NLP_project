{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Named Entity Recognition (NER) ####\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Entity      Type\n",
      "0     Apple Inc.       ORG\n",
      "1  New York City       GPE\n",
      "2           2024      DATE\n",
      "3       Tim Cook    PERSON\n",
      "4    last Friday      DATE\n",
      "5      Manhattan       GPE\n",
      "6    about 2,000  CARDINAL\n",
      "7             AI       ORG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple Inc.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is planning to open a new office in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York City\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " by \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". <br>The tech giant's CEO, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tim Cook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", announced the expansion during a press conference \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last Friday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". <br>The new office, located in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Manhattan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", will create \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    about 2,000\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " jobs in various sectors including \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AI\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and machine learning.<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizations: ['Apple Inc.', 'AI']\n",
      "People: ['Tim Cook']\n",
      "Dates: ['2024', 'last Friday']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample text (you can replace this with real-world data)\n",
    "text = \"\"\"\n",
    "Apple Inc. is planning to open a new office in New York City by 2024. \n",
    "The tech giant's CEO, Tim Cook, announced the expansion during a press conference last Friday. \n",
    "The new office, located in Manhattan, will create about 2,000 jobs in various sectors including AI and machine learning.\n",
    "\"\"\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(entities, columns=['Entity', 'Type'])\n",
    "print(df)\n",
    "\n",
    "# Visualize the entities in the text\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n",
    "# Function to extract specific entity types\n",
    "def extract_entity_type(text, entity_type):\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents if ent.label_ == entity_type]\n",
    "\n",
    "# Example usage\n",
    "organizations = extract_entity_type(text, \"ORG\")\n",
    "people = extract_entity_type(text, \"PERSON\")\n",
    "dates = extract_entity_type(text, \"DATE\")\n",
    "\n",
    "print(f\"Organizations: {organizations}\")\n",
    "print(f\"People: {people}\")\n",
    "print(f\"Dates: {dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Summarizer ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.43.1-py3-none-any.whl (9.4 MB)\n",
      "     ---------------------------------------- 9.4/9.4 MB 741.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.24.1-py3-none-any.whl (417 kB)\n",
      "     -------------------------------------- 417.2/417.2 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 2.4 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "     ------------------------------------- 287.9/287.9 kB 86.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.24.1 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.43.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fa965b7c15410692030d2b485320df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\AADITI\\.cache\\huggingface\\hub\\models--facebook--bart-large-cnn. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee48abcba5749498ac4484ee9c554f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26096\\758360533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load pre-trained model and tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBartForConditionalGeneration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/bart-large-cnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"facebook/bart-large-cnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3491\u001b[0m                         \u001b[1;34m\"_commit_hash\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3492\u001b[0m                     }\n\u001b[1;32m-> 3493\u001b[1;33m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m                     \u001b[1;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;31m# Load from URL or cache if already cached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"\\n\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcustom_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         )\n\u001b[0;32m   1239\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[0;32m   1241\u001b[0m             \u001b[1;31m# Destination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m         _download_to_tmp_and_move(\n\u001b[0m\u001b[0;32m   1390\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".incomplete\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[0;32m   1913\u001b[0m             \u001b[0m_check_disk_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m         http_get(\n\u001b[0m\u001b[0;32m   1916\u001b[0m             \u001b[0murl_to_download\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[0mnew_resume_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDOWNLOAD_CHUNK_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# filter out keep-alive new chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"stream\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 820\u001b[1;33m                     \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    821\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    947\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m                 \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[1;31m# StringIO doesn't like amt=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     def _raw_read(\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\AADITI\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "def summarize_text(text, max_length=150, min_length=50):\n",
    "    # Encode the text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "article = \"\"\"\n",
    "The United Nations Climate Change Conference, more commonly referred to as COP26, was held in Glasgow, Scotland, United Kingdom, from 31 October to 13 November 2021. The conference was the 26th United Nations Climate Change conference and brought together parties to accelerate action towards the goals of the Paris Agreement and the UN Framework Convention on Climate Change.\n",
    "\n",
    "The conference was originally scheduled to be held in 2020, but was postponed due to the COVID-19 pandemic. More than 190 world leaders participated, along with tens of thousands of negotiators, government representatives, businesses and citizens for twelve days of talks.\n",
    "\n",
    "The main goals of COP26 were to secure global net-zero emissions by mid-century and keep 1.5 degrees Celsius of warming within reach, adapt to protect communities and natural habitats, mobilize finance, and work together to deliver on climate action promises.\n",
    "\n",
    "Key outcomes of the conference included new pledges from some countries to cut emissions, a global agreement to reduce coal use, and promises of increased financial support for developing countries. However, many activists and experts argued that the commitments made at COP26 were not ambitious enough to effectively address the climate crisis.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize_text(article)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "\n",
      "The United Nations Climate Change Conference, more commonly referred to as COP26, was held in Glasgow, Scotland, United Kingdom, from 31 October to 13 November 2021. More than 190 world leaders participated, along with tens of thousands of negotiators, government representatives, businesses and citizens for twelve days of talks. The main goals of COP26 were to secure global net-zero emissions by mid-century and keep 1.5 degrees Celsius of warming within reach, adapt to protect communities and natural habitats, mobilize finance, and work together to deliver on climate action promises.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\AADITI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AADITI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from heapq import nlargest\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def simple_summarize(text, num_sentences=3):\n",
    "    # Tokenize the text into sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    freq = FreqDist(words)\n",
    "    \n",
    "    # Score sentences based on word frequencies\n",
    "    scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for word in word_tokenize(sentence.lower()):\n",
    "            if word in freq:\n",
    "                if i not in scores:\n",
    "                    scores[i] = freq[word]\n",
    "                else:\n",
    "                    scores[i] += freq[word]\n",
    "    \n",
    "    # Get the top n sentences\n",
    "    top_sentences = nlargest(num_sentences, scores, key=scores.get)\n",
    "    \n",
    "    # Sort the sentences by their original order\n",
    "    top_sentences.sort()\n",
    "    \n",
    "    # Join the top sentences\n",
    "    summary = ' '.join([sentences[i] for i in top_sentences])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "article = \"\"\"\n",
    "The United Nations Climate Change Conference, more commonly referred to as COP26, was held in Glasgow, Scotland, United Kingdom, from 31 October to 13 November 2021. The conference was the 26th United Nations Climate Change conference and brought together parties to accelerate action towards the goals of the Paris Agreement and the UN Framework Convention on Climate Change.\n",
    "\n",
    "The conference was originally scheduled to be held in 2020, but was postponed due to the COVID-19 pandemic. More than 190 world leaders participated, along with tens of thousands of negotiators, government representatives, businesses and citizens for twelve days of talks.\n",
    "\n",
    "The main goals of COP26 were to secure global net-zero emissions by mid-century and keep 1.5 degrees Celsius of warming within reach, adapt to protect communities and natural habitats, mobilize finance, and work together to deliver on climate action promises.\n",
    "\n",
    "Key outcomes of the conference included new pledges from some countries to cut emissions, a global agreement to reduce coal use, and promises of increased financial support for developing countries. However, many activists and experts argued that the commitments made at COP26 were not ambitious enough to effectively address the climate crisis.\n",
    "\"\"\"\n",
    "\n",
    "summary = simple_summarize(article)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chatbot Development ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.chat.util import Chat, reflections\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "import datetime\n",
    "\n",
    "# Download necessary NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Define patterns and responses\n",
    "patterns = [\n",
    "    (r'hi|hello|hey', ['Hello!', 'Hi there!', 'Hey!']),\n",
    "    (r'how are you', [\"I'm doing well, thank you!\", \"I'm fine, how about you?\"]),\n",
    "    (r'what is your name', [\"My name is ChatBot.\", \"I'm ChatBot, nice to meet you!\"]),\n",
    "    (r'bye|goodbye', ['Goodbye!', 'See you later!', 'Bye!']),\n",
    "    (r'what can you do', ['I can answer simple questions and engage in basic conversation.']),\n",
    "    (r'(.*) weather (.*)', [\"I'm sorry, I don't have access to real-time weather information.\"]),\n",
    "    (r'(.*) (love|like) (.*)', [\"That's great! I'm glad you enjoy that.\"]),\n",
    "    (r'(.*) (hate|dislike) (.*)', [\"I'm sorry to hear that. Maybe we can talk about something you like instead?\"]),\n",
    "    (r'(.*)', [\"I'm not sure I understand. Could you rephrase that?\", \"Interesting. Tell me more about that.\"])\n",
    "]\n",
    "\n",
    "# Create the chatbot\n",
    "chatbot = Chat(patterns, reflections)\n",
    "\n",
    "# Function to handle sending messages\n",
    "def send_message():\n",
    "    user_input = user_entry.get()\n",
    "    chat_history.insert(tk.END, \"You: \" + user_input + \"\\n\")\n",
    "    response = chatbot.respond(user_input)\n",
    "    chat_history.insert(tk.END, \"ChatBot: \" + response + \"\\n\\n\")\n",
    "    user_entry.delete(0, tk.END)\n",
    "    \n",
    "    # Store the conversation\n",
    "    with open(\"chat_history.txt\", \"a\") as file:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        file.write(f\"{timestamp}\\n\")\n",
    "        file.write(f\"User: {user_input}\\n\")\n",
    "        file.write(f\"ChatBot: {response}\\n\\n\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"ChatBot GUI\")\n",
    "\n",
    "# Create and pack the chat history display\n",
    "chat_history = scrolledtext.ScrolledText(root, width=50, height=20)\n",
    "chat_history.pack(padx=10, pady=10)\n",
    "\n",
    "# Create and pack the user input field\n",
    "user_entry = tk.Entry(root, width=50)\n",
    "user_entry.pack(padx=10, pady=5)\n",
    "\n",
    "# Create and pack the send button\n",
    "send_button = tk.Button(root, text=\"Send\", command=send_message)\n",
    "send_button.pack(pady=5)\n",
    "\n",
    "# Start the GUI event loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Translation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "     -------------------------------------- 991.5/991.5 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "     ------------------------------------ 897.5/897.5 kB 945.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from sacremoses) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from sacremoses) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from sacremoses) (1.1.0)\n",
      "Requirement already satisfied: regex in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from sacremoses) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\aaditi\\anaconda3\\lib\\site-packages (from click->sacremoses) (0.4.6)\n",
      "Installing collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Dictionary to hold models and tokenizers\n",
    "models = {}\n",
    "tokenizers = {}\n",
    "\n",
    "def get_model_and_tokenizer(source_lang, target_lang):\n",
    "    model_name = f'Helsinki-NLP/opus-mt-{source_lang}-{target_lang}'\n",
    "    if model_name not in models:\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        models[model_name] = model\n",
    "        tokenizers[model_name] = tokenizer\n",
    "    else:\n",
    "        model = models[model_name]\n",
    "        tokenizer = tokenizers[model_name]\n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to perform translation\n",
    "def translate_text(text, source_lang, target_lang):\n",
    "    try:\n",
    "        model, tokenizer = get_model_and_tokenizer(source_lang, target_lang)\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "        translated = model.generate(**inputs)\n",
    "        translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "        return translated_text\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Translation Error\", str(e))\n",
    "        return \"\"\n",
    "\n",
    "# Function to handle the translation button click\n",
    "def on_translate():\n",
    "    source_text = source_text_entry.get(\"1.0\", tk.END).strip()\n",
    "    if not source_text:\n",
    "        messagebox.showwarning(\"Input Error\", \"Please enter text to translate\")\n",
    "        return\n",
    "    source_lang = source_lang_combo.get()\n",
    "    target_lang = target_lang_combo.get()\n",
    "    source_lang_code = lang_to_code[source_lang]\n",
    "    target_lang_code = lang_to_code[target_lang]\n",
    "    translated_text = translate_text(source_text, source_lang_code, target_lang_code)\n",
    "    translated_text_entry.delete(\"1.0\", tk.END)\n",
    "    translated_text_entry.insert(tk.END, translated_text)\n",
    "\n",
    "# Mapping of languages to their codes\n",
    "lang_to_code = {\n",
    "    \"English\": \"en\",\n",
    "    \"Spanish\": \"es\",\n",
    "    \"French\": \"fr\",\n",
    "    \"German\": \"de\",\n",
    "    \"Italian\": \"it\",\n",
    "    \"Portuguese\": \"pt\",\n",
    "    \"Dutch\": \"nl\",\n",
    "    \"Russian\": \"ru\",\n",
    "    \"Chinese\": \"zh\",\n",
    "    \"Japanese\": \"ja\"\n",
    "}\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Translation System\")\n",
    "root.geometry(\"600x400\")\n",
    "\n",
    "# Source language label and combo box\n",
    "source_lang_label = ttk.Label(root, text=\"Source Language:\")\n",
    "source_lang_label.pack(pady=5)\n",
    "source_lang_combo = ttk.Combobox(root, values=list(lang_to_code.keys()), state=\"readonly\")\n",
    "source_lang_combo.pack(pady=5)\n",
    "source_lang_combo.set(\"English\")\n",
    "\n",
    "# Target language label and combo box\n",
    "target_lang_label = ttk.Label(root, text=\"Target Language:\")\n",
    "target_lang_label.pack(pady=5)\n",
    "target_lang_combo = ttk.Combobox(root, values=list(lang_to_code.keys()), state=\"readonly\")\n",
    "target_lang_combo.pack(pady=5)\n",
    "target_lang_combo.set(\"Spanish\")\n",
    "\n",
    "# Source text entry\n",
    "source_text_label = ttk.Label(root, text=\"Enter text to translate:\")\n",
    "source_text_label.pack(pady=5)\n",
    "source_text_entry = tk.Text(root, height=5, width=70)\n",
    "source_text_entry.pack(pady=5)\n",
    "\n",
    "# Translate button\n",
    "translate_button = ttk.Button(root, text=\"Translate\", command=on_translate)\n",
    "translate_button.pack(pady=5)\n",
    "\n",
    "# Translated text entry\n",
    "translated_text_label = ttk.Label(root, text=\"Translated text:\")\n",
    "translated_text_label.pack(pady=5)\n",
    "translated_text_entry = tk.Text(root, height=5, width=70)\n",
    "translated_text_entry.pack(pady=5)\n",
    "\n",
    "# Run the main loop\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
